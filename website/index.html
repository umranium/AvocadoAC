<?xml version="1.0"?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Android projects by Chris Smith</title>
    <link rel="stylesheet" type="text/css" href="http://chris.smith.name/style.css"/>
    <style type="text/css">
     .sidebar { float: left; clear: left; margin-right: 15px; width: 128px; }
     .sidebar img { width: 128px; margin-bottom: 10px; } 
     div.main { margin-left: 143px; }
     h3 { border-bottom: 1px solid #ccc; clear: both; }
    </style>
  </head>
  <body style="margin-top: 0; padding-top: 0;">
    <h1 style="background: url('android.png') no-repeat right; padding-top: 50px; margin-top: 0;">Android projects by <span>Chris Smith</span></h1>
    <div>
     <h2>Context-aware framework</h2>
     <p>
      The goal of the context-aware framework is to create an open, easy-to-use
      framework for application developers to retrieve information about the
      user's context. This context information includes low-level activites
      (walking, sitting, running, etc), places (home, work, travelling),
      nearby people (friends, strangers, etc) and more.
     </p>
     <p>
      At present the project is in a research and data-collection phase. The
      applications presented below are intended to assist in gathering data
      which can be analysed to determine suitable algorithms and parameters
      to perform the detection necessary to correctly classify and extract
      context information. While they are published on the Android market
      and freely available to download, they do not provide much benefit to
      end users, so it is not anticipated that they will be widely used
      outside a small set of voluntary testers.
     </p>
     <p>
      Issues, suggestions and feedback can be sent to me directly (either via
      the address published on the application's market page, or the details
      on my <a href="http://chris.smith.name/">home page</a>), or raised as
      issues on the project page over at
      <a href="http://github.com/csmith/ContextApi/issues">GitHub</a>.
     </p>
     <div class="app">
      <h3>Sensor Logger</h3>
      <div class="sidebar">
       <a href="market://details?id=uk.co.md87.android.sensorlogger" class="qr">
        <img src="SensorLogger.png" alt="SensorLogger.apk QR code">
       </a>
       <a href="res/sensorlogger/introscreenshot.png">
        <img src="res/sensorlogger/introscreenshot.png" alt="Sensor Logger introduction screenshot"/>
       </a>
       <a href="res/sensorlogger/resultsscreenshot.png">
        <img src="res/sensorlogger/resultsscreenshot.png" alt="Sensor Logger results screenshot"/>
       </a>
      </div>
      <div class="main">
       <p>
        The Sensor Logger logs data from your device's accelerometer, magnetic field, and orientation sensors.
        It then uses some of this data to try and determine what activity you were performing.
       </p>
       <p>
        Once you've confirmed or corrected the activity prediction, the sensor data, guessed activity, and
        any corrections made are sent to this website, where they can be analysed to help improve the
        algorithm in the future.
       </p>
       <p>
        At present, the Sensor Logger can (try to!) classify: walking (normally, up stairs, and down stairs),
        standing, sitting, travelling by bus, travelling by car, and dancing. If you regularly perform any
        other activity with your phone on you, please run the application and submit a correction and it can
        be included in future versions!
       </p>
       <p>
        You can review the data you submit on this website. Just follow the unique link from the Sensor Logger
        application to see graphs of your sensor readings, details about how the data has been manually classified
        (if applicable), and a graphical representation of how the data is split up into discrete windows.
       </p>
       <h4>Changelog</h4>
       <ul>
        <li><strong>0.2.3 &rarr; 0.2.4</strong>: Added analytics</li>
        <li><strong>0.2.2 &rarr; 0.2.3</strong>: Fix another force close, updated model for classification</li>
        <li><strong>0.2.1 &rarr; 0.2.2</strong>: Fix force close, add reporting of exceptions</li>
        <li><strong>0.2.0 &rarr; 0.2.1</strong>: Bug fix related to turning display off</li>
        <li><strong>0.1.6 &rarr; 0.2.0</strong>: Near-complete rewrite: much improved UI, classification on device, bug fixes</li>
        <li><strong>0.1.5 &rarr; 0.1.6</strong>: Fix force close on devices that use MEIDs not IMEI numbers</li>
        <li><strong>0.1.4 &rarr; 0.1.5</strong>: Make edit boxes single line only</li>
        <li><strong>0.1.3 &rarr; 0.1.4</strong>: Add support for horizontal layout</li>
        <li><strong>0.1.2 &rarr; 0.1.3</strong>: Added link to portal webpage</li>
        <li><strong>0.1.1 &rarr; 0.1.2</strong>: Fix force close when no magnetic field sensors are available, disable upload button</li>
        <li><strong>0.1.0 &rarr; 0.1.1</strong>: Add 10s delay at start, disable auto start, disable manual stopping, fix various uploader bugs</li>
       </ul>
      </div>
     </div>
     <div class="app">
      <h3>Activity Recorder</h3>
      <div class="sidebar">
       <a href="market://details?id=uk.co.md87.android.activityrecorder" class="qr">
        <img src="ActivityRecorder.png" alt="ActivityRecorder.apk QR code">
       </a>
       <!--<a href="res/sensorlogger/introscreenshot.png">
        <img src="res/sensorlogger/introscreenshot.png" alt="Sensor Logger introduction screenshot"/>
       </a>
       <a href="res/sensorlogger/resultsscreenshot.png">
        <img src="res/sensorlogger/resultsscreenshot.png" alt="Sensor Logger results screenshot"/>
       </a>-->
      </div>
      <div class="main">
       <p>
        The Activity Recorder performs similar activity classification to the
        Sensor Logger, but does it periodically in a background service. The
        collected data can be viewed in a basic list. 
       </p>
       <p>
        This will be the basis for the main context-aware framework &mdash;
        additional sources of information (location, noise, etc) will be
        integrated, and the service will eventually provide an API for other
        applications to listen out for changes in the user's activity.
       </p>
       <p>
        The classification algorithm now uses scores assigned to each possible
        classification instead of merely using the results from the last
        set of sensor input. This means that the classifications may be
        slightly delayed (it will take a minute or so to react to changes in
        activity), but it makes the algorithm much more tolerant of occasional
        erroneous readings.
       </p>
       <h4>Changelog</h4>
       <ul>
        <li><strong>0.2.0 &rarr; 0.2.1</strong>: Added analytics</li>
        <li><strong>0.1.3 &rarr; 0.2.0</strong>: Changed classification algorithm to favour existing classifications, change recording to one sample every 30 seconds instead of 2 overlapping samples every 60 seconds, disable logging, durations measured in seconds now show as "&lt;1 min"</li>
        <li><strong>0.1.2 &rarr; 0.1.3</strong>: More efficient updating of activity list, give feedback when starting service</li>
        <li><strong>0.1.1 &rarr; 0.1.2</strong>: Fix various issues when starting service</li>
        <li><strong>0.1.0 &rarr; 0.1.1</strong>: Fix exception when stopping service in some conditions</li>
       </ul>
      </div>
     </div>
    </div>
    <div id="footer"/>
  </body>
</html>
